<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Some Standard Multimedia Compression Techniques</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part523.htm">&lt; Назад</a><span> | </span><a href="../index.html">Содержимое</a><span> | </span><a href="part525.htm">Далее &gt;</a></p><p style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;"><a href="#bookmark522" name="bookmark2374">Some Standard Multimedia Compression Techniques</a><a name="bookmark2428">&zwnj;</a></p><p style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;">Over the years, several standards have evolved for compression and decompression of multimedia objects. Some commonly used standards are described here. For this description, we have selected one each for still image, video, and audio media.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">JPEG (Joint Photographic Experts Group)</h4><p style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;">JPEG is the standard compression technique for still images. It is of reasonably low computational complexity, is capable of producing compressed images of high quality, and can provide both lossless and lossy compression of arbitrarily sized grayscale and color images. As will be clear from the explanation here, it is a hybrid of several basic compression methods. It supports the following four modes of encoding:</p><p style="padding-top: 9pt;padding-left: 23pt;text-indent: 0pt;text-align: justify;">1. <b>Sequential. </b>In this mode, it encodes the image in the order in which the image is scanned.</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: -15pt;text-align: justify;">2. <b>Progressive. </b>In this mode, it encodes the image in multiple passes, so that a user can visualize the entire content in a rough-to-clear process (i.e., refined during succeeding passes). This capability is convenient for browsing applications where a low-quality (low- resolution) image is adequate for things like scanning through the pages of a catalog, and when the user reaches the desired page, he/she can subject only that page to subsequent passes to display it more clearly (in high-resolution).</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: -15pt;text-align: justify;">3. <b>Hierarchical. </b>In this mode, it encodes the image at multiple resolutions to accommodate different types of displays.</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: -15pt;text-align: justify;">4. <b>Lossless. </b>In this mode, it encodes the image in such a way that it can fully restore original quality of the image.</p><p class="s46" style="padding-top: 9pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><a href="part524.htm#bookmark2429" class="s23">JPEG uses DCT encoding and quantization for the first three modes, and uses predictive encoding for the lossless mode. Since quantization is a lossy algorithm, the first three modes of encoding are lossy. The basic steps of lossy JPEG compression (shown in </a><a href="part524.htm#bookmark2429" class="s3">Figure </a>14.9<span class="p">) are as follows (decoder performs the inverse operations):</span></p><p style="padding-top: 9pt;padding-left: 38pt;text-indent: -15pt;text-align: justify;">1. If the image is a color image, the method transforms <i>RGB </i>color space to <i>YUV </i>color space and down-samples chrominance component (the color) to exploit color redundancy. If the image is a grayscale image, the method does not perform this step.</p><p style="padding-top: 4pt;padding-left: 23pt;text-indent: 0pt;text-align: justify;">2. It then divides the image into a series of blocks of 8 x 8 pixels.</p><p style="padding-top: 4pt;padding-left: 38pt;text-indent: -15pt;text-align: justify;">3. It then applies DCT transformation to each such 8 x 8 block of pixels to exploit spatial redundancy.</p><p style="padding-top: 4pt;padding-left: 38pt;text-indent: -15pt;text-align: justify;">4. It then scalar quantizes the resulting DCT coefficient (the 64 frequency component in each block) using a quantization-table (Q-table).</p><p style="padding-top: 4pt;padding-left: 38pt;text-indent: -15pt;text-align: justify;">5. It then orders the resulting 2-D output of quantization in a zigzag sequence, creating a bit stream with zero-value coefficients close to the end, since it places low-frequency components (most likely nonzero) in front of high-frequency components (most likely zero).</p><p style="padding-top: 4pt;padding-left: 23pt;text-indent: 0pt;text-align: justify;">6. It then applies run-length encoding to zeros of the zigzag sequence.</p><p style="padding-top: 4pt;padding-left: 23pt;text-indent: 0pt;text-align: justify;">7. Finally, it applies variable-length encoding on the run-length coded stream to obtain the</p><p style="padding-top: 3pt;padding-left: 39pt;text-indent: 0pt;text-align: left;">JPEG compressed stream.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 154pt;text-indent: 0pt;text-align: left;"><span><img width="227" height="566" alt="image" src="Image_770.jpg"/></span></p><p class="s20" style="padding-top: 8pt;padding-left: 8pt;text-indent: 0pt;text-align: center;"><a name="bookmark2429">Figure 14.9. </a><span class="s21">Steps of lossy JPEG compression.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"><a href="part524.htm#bookmark2429" class="s23" name="bookmark2430">Lossless mode of JPEG compression uses a different method than the lossy method of </a><a href="part524.htm#bookmark2429" class="s3">Figure</a></p><p class="s46" style="padding-left: 6pt;text-indent: 0pt;text-align: justify;"><a href="part524.htm#bookmark2429" class="s3">14.9</a><a href="part524.htm#bookmark2429" class="s23">. Fundamentally, it handles the image pixels separately (i.e., it does not use the 8 x 8 </a><a href="part524.htm#bookmark2431" class="s23">block structure), and predicts each pixel based on three adjacent pixels using one of the eight possible predictor modes. The basic steps of lossless JPEG compression (shown in </a><a href="part524.htm#bookmark2431" class="s3">Figure </a>14.10<span class="p">) are as follows (decoder performs the inverse operations):</span></p><p style="padding-top: 9pt;padding-left: 39pt;text-indent: -15pt;text-align: left;">1. It first applies a simple predictive coding scheme to the image. For this, it handles each pixel of the image separately.</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: -15pt;text-align: left;">2. It then uses a variable-length encoder to encode the predicted pixels in lossless manner to obtain the JPEG compressed bit stream.</p><p style="padding-left: 100pt;text-indent: 0pt;text-align: left;"><span><img width="373" height="130" alt="image" src="Image_771.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s20" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: center;"><a name="bookmark2431">Figure 14.10. </a><span class="s21">Steps of lossless JPEG compression.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">MPEG Video</h4><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">MPEG (Motion Pictures Experts Group) is a multimedia standard with specifications for coding, compression, and transmission of audio, video, and data streams in a series of synchronized, mixed packets. MPEG video standard is a subset of MPEG standard. It can compress a wide range of video and motion pictures. It defines the structure of coded video bit streams transmitted to the decoder and the decoder architecture, but leaves the encoder architecture undefined, so that some encoders may produce higher quality compression, some may be real-time, and some may require manual intervention. MPEG compression is lossy and asymmetric, with encoding process requiring more time than decoding process.</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">Digital video compression techniques either apply intra-frame compression to each individual frame of the video, or combine both intra-frame and inter-frame compression. The former scheme yields a lower compression ratio than the latter because it does not exploit temporal redundancy. Differential encoding is one approach to remove temporal redundancy. It encodes and sends the differences in adjacent frames. Motion compensation is another technique for inter-frame compression. It compares the current frame with the previous one and encodes the motion vectors (i.e., the change in coordinate values due to the motion) and pixel differences after motion. MPEG uses both intra-frame and inter-frame techniques for data compression.</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">In MPEG, encoded frames are of the following three types:</p><p style="padding-top: 9pt;padding-left: 38pt;text-indent: -15pt;text-align: justify;">1. <b>I (Intra-frame). </b>An I-frame is coded independently of any other frame in the video sequence. Hence, it contains all information that is necessary to reproduce a complete frame. It applies intra-frame compression of basic JPEG DCT algorithm.</p><p style="padding-top: 4pt;padding-left: 38pt;text-indent: -15pt;text-align: justify;">2. <b>P (Predicted). </b>A P-frame is predicted from the differences from the previous I- or P- frame in the sequence.</p><p style="padding-top: 4pt;padding-left: 38pt;text-indent: -15pt;text-align: justify;">3. <b>B (Bidirectional). </b>A B-frame is bidirectional interpolated by the preceding and the subsequent I- or P- frames.</p><p class="s46" style="padding-top: 9pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><a href="part524.htm#bookmark2432" class="s23">Note that due to inter-frame dependency in case of P-frames and B-frames, a current P-frame can be decoded only if the preceding I- or P-frame has been presented for decoding. Similarly, without the preceding and the subsequent I- or P-frame in the decoder, it is impossible to generate  a  B-frame.  For  example,  if  the  presentation  order  of  a  video  sequence  is IBBPBBPBBI….., then the actual input sequence of MPEG frames to a decoder should be IPBBPBBIBB….. (see </a><a href="part524.htm#bookmark2432" class="s3">Figure </a>14.11<span class="p">). Therefore, patterns of video frame sequence in storage and during transmission are different from that for presentation.</span></p><p style="padding-left: 88pt;text-indent: 0pt;text-align: left;"><a name="bookmark2433"><span><img width="405" height="260" alt="image" src="Image_772.jpg"/></span></a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s20" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: center;"><a name="bookmark2432">Figure 14.11. </a><span class="s21">Patterns of video frame sequence in storage and during transmission</span></p><p style="padding-top: 9pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">are different from that for presentation in case of MPEG compression of video.</p><p class="s46" style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a href="part524.htm#bookmark2434" class="s23">Basic steps of MPEG compression (shown in </a>Figure 14.12<span class="p">) are as follows (decoder performs the inverse operations):</span></p><p style="padding-top: 9pt;padding-left: 39pt;text-indent: -15pt;text-align: justify;">1. The method preprocesses individual frames of video data to be compressed and performs color sub-sampling on them to carry out the first level of compression. Recall that color sub-sampling approach shrinks data size by down-sampling chrominance component (i.e., using less bits to represent chrominance component) while leaving luminance component unchanged.</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: -15pt;text-align: justify;">2. It then performs inter-frame motion compensation for the frames of types P and B to carry out the second level of compression. Frames of type I do not need this step because the method applies only intra-frame compression to these frames.</p><p style="padding-top: 4pt;padding-left: 23pt;text-indent: 0pt;text-align: justify;">3. It then divides each frame into a series of blocks of 8 x 8 pixels.</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: -15pt;text-align: left;">4. It then applies DCT transformation to each such 8 x 8 block of pixels to exploit spatial redundancy.</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: -15pt;text-align: left;">5. It then scalar quantizes the resulting DCT coefficients (64 frequency components in each block) using a quantization table (Q-table).</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: -15pt;text-align: left;">6. It then orders the resulting 2-D output of quantization in a zigzag sequence, creating a bit stream with zero-value coefficients close to the end.</p><p style="padding-top: 4pt;padding-left: 23pt;text-indent: 0pt;text-align: left;">7. It then applies run-length encoding to zeros of the zigzag sequence.</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: -15pt;text-align: left;">8. Finally, it applies variable-length encoding on the run-length coded stream to obtain the MPEG compressed video stream.</p><p style="padding-left: 84pt;text-indent: 0pt;text-align: left;"><span><img width="416" height="285" alt="image" src="Image_773.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s20" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: center;"><a name="bookmark2434">Figure 14.12. </a><span class="s21">Basic steps of MPEG compression.</span></p><p style="padding-top: 9pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">MPEG standard has the following versions:</p><p style="padding-top: 9pt;padding-left: 39pt;text-indent: -15pt;text-align: justify;">1. <b>MPEG-1. </b>Researchers developed MPEG-1 standard in response to industry need for an efficient way of storing and retrieving video information on digital storage media. CD- ROM being one such inexpensive medium, the first version of MPEG, MPEG-1, targeted CD-ROM and applications at a bit rate of about 1.5 Mb/s. Although MPEG-1 targeted CD-ROM, it was useful for other storage and transmission media such as DAT, Winchester disk, optical disk, ISDN, and LAN. In fact, data rate in MPEG-1 standard is variable and all decoders must be able to decode at rates up to 1.856 Mb/s. The video is strictly progressive (i.e., non-interlaced) and picture quality is equivalent to VHS.</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: -15pt;text-align: justify;">2. <b>MPEG-2. </b>Researchers developed MPEG-2 standard to provide the capability to compress, code, and transmit high quality, multichannel, multimedia signals over broadband networks. It addresses high quality coding for all digital transmissions of broadcast-TV-quality video at data rates of 2-15 Mb/s. Its major applications include digital storage media, digital television (including HDTV), broadcasting over cable, satellite, and other broadcast channels, and other communications applications. Since MPEG-2 is primarily a transmission standard, it supports a variety of packet formats (including long and variable-length packets ranging from 1 KB to 64 KB) and provides error-correction capability that is suitable for transmission over cable and satellite links.</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: 0pt;text-align: justify;">MPEG-2 is backward compatible with MPEG-1. Primary enhancements in MPEG-2 are for adding interlaced video. Hence, there are two coding structures (field and frame) in MPEG-2. Other enhancements include those for coding efficiency.</p><p style="padding-top: 4pt;padding-left: 38pt;text-indent: -15pt;text-align: justify;">3. <b>MPEG-4. </b>Focus of video coding gradually shifted to <i>object-based coding </i>at bit rates of 8 Kb/s or lower and 1 Mb/s or higher. To take care of this, researchers developed MPEG-4 standard, which has the following features:</p><p style="padding-top: 8pt;padding-left: 53pt;text-indent: 0pt;text-align: left;">a. Independent coding of objects in a picture frame;</p><p style="padding-top: 4pt;padding-left: 53pt;text-indent: 0pt;text-align: left;">b. Ability to interactively composite these objects into a scene at the display;</p><p style="padding-top: 3pt;padding-left: 54pt;text-indent: 0pt;text-align: left;">c. Ability to combine graphics, animated, and natural objects in the scene; and</p><p style="padding-top: 4pt;padding-left: 53pt;text-indent: 0pt;text-align: left;">d. Ability to transmit scenes in higher dimensionality formats (e.g., 3-D).</p><p style="padding-top: 8pt;padding-left: 39pt;text-indent: 0pt;text-align: justify;"><a name="bookmark2435">It also supports the concept of video scalability (both in temporal and spatial domains) to control video bit rate effectively at the transmitter, in the network, and at the receiver. With this feature, it can match available transmission and processing resources.</a></p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: 0pt;text-align: justify;">MPEG-4 builds on and combines elements from three fields - digital television, interactive graphics, and the World Wide Web. It provides a merging of production, distribution, and display elements of these three fields.</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: -15pt;text-align: justify;">4. <b>MPEG-7: </b>MPEG-7 is formally known as <i>Multimedia Content Description Interface</i>. It is a generic standard for a variety of applications. It provides a set of tools for completely describing multimedia content. It also supports some degree of interpretation of the content (such as which information is accessible by a device or a computer code).</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: -15pt;text-align: justify;">5. <b>MPEG-21: </b>MPEG-21 defines an open framework for multimedia content delivery and consumption for use by all types of users in delivery and consumption chain. It is based on the following two concepts:</p><p style="padding-top: 8pt;padding-left: 69pt;text-indent: -15pt;text-align: left;">a. <i>What of the multimedia framework</i>. This defines the digital item, which MPEG-21 uses as a fundamental unit of distribution and transaction.</p><p style="padding-top: 4pt;padding-left: 69pt;text-indent: -15pt;text-align: left;">b. <i>Who of the multimedia framework</i>. This deals with user requirements for interacting with digital items.</p><p style="padding-top: 9pt;padding-left: 39pt;text-indent: 0pt;text-align: justify;">MPEG-21, therefore, also defines the technology for supporting users to exchange, access, consume, trade, and manipulate digital items (multimedia content) in an efficient, transparent, and interoperable manner. For this, it includes<i>Rights Expression Language (REL) </i>and <i>Rights Data Dictionary (RDD)</i>. Unlike other MPEG standards that describe compression-coding methods, MPEG-21 describes a standard that defines description of content and processes for accessing, searching, storing, and protecting copyrights of content.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">MPEG Audio</h4><p style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;">MPEG audio is a standard for compression and decompression of digital audio. Researchers observed that spectral neighborhood of a strong audio signal consist of weaker audio signals, which are imperceptible to human ears. Based on measurements of human hearing sensitivity, they found that human ear integrates audio signals that are close in frequency and treats them as a group. The ear perceives loudness of each signal individually only when the signals are sufficiently different in frequency. Coding technique of MPEG audio standard (known as <i>perceptual coding</i>) takes advantage of this perceptual weakness of human ears (psychoacoustic phenomena). It divides the audio spectrum into a set of narrow frequency bands, called critical bands, to reflect frequency selectivity of human hearing. It then uses a filtering mechanism and filters coding noise sharply to force it to stay close to the frequency of frequency components of the audio signal being coded, thereby masking out the noise. By reducing coding noise when no audio is present and allowing strong audio to mask noise at other times, sound fidelity of original signals can be perceived perceptually.</p><p class="s46" style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;"><a href="part524.htm#bookmark2436" class="s3">Figure </a>14.13<span class="p">(a) shows the basic steps of MPEG audio (MPEG-1 audio, to be more precise)</span></p><p style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;">encoding, which are as follows:</p><p style="padding-top: 9pt;padding-left: 39pt;text-indent: -15pt;text-align: justify;">1. It first transforms the audio signal (to be compressed) from time domain to frequency domain.</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: -15pt;text-align: justify;">2. It then passes the resultant audio spectrum through a filter bank, which divides it into multiple sub-bands.</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: -15pt;text-align: justify;">3. Simultaneously, it subjects the input audio signal to a psychoacoustic model, which exploits auditory masking and determines the signal-to-noise ratio of each sub-band.</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: -15pt;text-align: justify;">4. It then quantizes each sub-band using a quantizer. It uses a bit/noise allocation algorithm to determine the number of code bits allocated to quantize each sub-band. In this manner, it minimizes audibility of quantization noise.</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: -15pt;text-align: justify;">5. It then formats the quantized samples into a series of bit streams, which is the encoded bit stream for the input audio signal.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 51pt;text-indent: 0pt;text-align: left;"><span><img width="502" height="226" alt="image" src="Image_774.jpg"/></span></p><p class="s20" style="padding-top: 9pt;padding-left: 8pt;text-indent: 0pt;text-align: center;"><a name="bookmark2436">Figure 14.13. </a><span class="s21">Basic steps of MPEG audio encoding and decoding.</span><a name="bookmark2437">&zwnj;</a></p><p class="s46" style="padding-top: 9pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;"><a href="part524.htm#bookmark2436" class="s23">As </a><a href="part524.htm#bookmark2436" class="s3">Figure </a>14.13<span class="p">(b) shows, the decoder performs the inverse operation of the encoder for reconstructing time-domain audio signal from encoded bit stream.</span></p><p style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;">To provide different quality and different bit rates, the standard supports three distinct layers for compression - Layer I is the most basic and simplest coding algorithm, and Layers II and III are enhancements of Layer I.</p><p style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;">Researchers later enhanced MPEG-1 audio standard to MPEG-2 audio for low-bit-rate coding of multichannel audio. It has 5.1 channels of audio, including three front channels (i.e., left, center, right) plus two surround channels, and a low-frequency bass-effect channel, called subwoofer. Since the subwoofer has only limited frequency response (about 100 Hz), it is also referred to as “.1” channel. MPEG-2 audio is backward compatible with MPEG-1 audio because it uses the same coding methods and syntax as that of MPEG-1 audio for the two main channels (left and right). However, MPEG-2 audio uses new coding methods and syntax for surround channels.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part523.htm">&lt; Назад</a><span> | </span><a href="../index.html">Содержимое</a><span> | </span><a href="part525.htm">Далее &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
