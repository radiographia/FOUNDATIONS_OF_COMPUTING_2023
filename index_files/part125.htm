<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Shared Memory Systems</title><link href="navigation.css" rel="stylesheet" type="text/css"/><link href="document.css" rel="stylesheet" type="text/css"/></head><body><p class="top_nav"><a href="part124.htm">&lt; Назад</a><span> | </span><a href="../index.html">Содержимое</a><span> | </span><a href="part126.htm">Далее &gt;</a></p><p style="padding-top: 6pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;"><a href="#bookmark123" name="bookmark943">Shared Memory Systems</a><a name="bookmark1014">&zwnj;</a></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">These systems have a single system-wide primary memory, which all processors share (see Fig. 4.14)<i>. </i>If any processor writes, for example, value 100 to memory location <i>x, </i>any other processor subsequently reading from location <i>x </i>will get the value 100. Therefore, in these systems, any communication between processors usually takes place through the shared memory.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 98pt;text-indent: 0pt;text-align: left;"><span><img width="378" height="90" alt="image" src="Image_327.jpg"/></span></p><p class="s20" style="padding-top: 9pt;padding-left: 8pt;text-indent: 0pt;text-align: center;"><a name="bookmark1015">Figure 4.14. </a><span class="s21">Basic architecture of a shared memory multiprocessor system.</span></p><p class="s46" style="padding-top: 9pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;"><a href="part125.htm#bookmark1015" class="s23">The interconnection hardware of </a><a href="part125.htm#bookmark1015" class="s3">Figure </a>4.14<span class="s10"> </span><span class="p">can be organized in several different ways. Depending on this, some commonly known architectures of shared memory systems are:</span></p><p style="padding-top: 9pt;padding-left: 39pt;text-indent: -15pt;text-align: justify;">1. <b>Shared bus architecture. </b><a href="part125.htm#bookmark1016" class="s23">As </a><a href="part125.htm#bookmark1016" class="s3">Figure </a><span class="s46">4.15</span>(a) shows, a system having this architecture connects multiple CPUs through a common bus to memory unit (comprised of multiple memory modules). Physically, the system uses a high-speed backplane to insert CPU and memory cards. The CPUs time-share the common bus for memory accesses. That is, only one processor can access the memory at a time (the processor that is in control of the bus at the time). This means that when one processor is communicating with the memory, all other processors are either busy with internal operations or must be idle waiting for the bus. As the number of processors increases, contention for the shared bus increases and system overhead for conflicts resolution considerably goes up, resulting in significant drop in overall system performance. Hence, this architecture does not scale beyond a few CPUs (cannot support large number of processors).</p><p style="padding-top: 4pt;padding-left: 23pt;text-indent: 0pt;text-align: justify;">2. <b>Shared bus with cache memory architecture. </b><a href="part125.htm#bookmark1016" class="s23">As </a><span class="s46">Figure 4.15</span>(b) shows, a system having</p><p style="padding-top: 3pt;padding-left: 39pt;text-indent: 0pt;text-align: justify;">this architecture uses a high-speed cache memory between each CPU and the bus to reduce contention for the shared bus. Each cache memory holds the most recently accessed words by its own CPU and all memory access requests of a CPU go through its cache. If a CPU finds an accessed memory word in its cache (case of cache hit), it services the access request from the cache itself and does not make any bus request. Hence, if cache memories are large enough, cache hit rates will be high, resulting in reduced contention for the shared bus.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 90pt;text-indent: 0pt;text-align: left;"><span><img width="444" height="523" alt="image" src="Image_328.jpg"/></span></p><p class="s20" style="padding-top: 8pt;padding-left: 140pt;text-indent: -81pt;text-align: left;"><a name="bookmark1016">Figure 4.15. </a><span class="s21">A few examples of different architectures of shared memory multiprocessor systems depending on the type of interconnection hardware used.</span></p><p style="padding-top: 9pt;padding-left: 38pt;text-indent: 0pt;text-align: justify;">Since this architecture reduces contention for the shared bus, it may first appear that it is highly scalable (can support large number of processors). However, this is not true because cache memories introduce the requirement of dealing with incoherent memory. That is, if a system using this architecture caches the same memory word in cache memories of two or more CPUs, and if one of the CPUs overwrites the word, it must invalidate the word in cache memories of all other CPUs to prevent other CPUs from getting the old value from their own caches. System overhead involved in dealing with</p><p style="padding-top: 3pt;padding-left: 39pt;text-indent: 0pt;text-align: justify;">this cache consistency issue increases with the number of caches (CPUs). Hence, this architecture also does not scale beyond a few more CPUs than the shared bus architecture.</p><p style="padding-top: 3pt;padding-left: 38pt;text-indent: -15pt;text-align: justify;"><a name="bookmark1017">3. </a><b>Multiport memory architecture. </b><a href="part125.htm#bookmark1016" class="s23">As </a><a href="part125.htm#bookmark1016" class="s3">Figure </a><span class="s46">4.15</span>(c) shows, a system having this architecture avoids contention for a single shared bus by having a separate bus between each memory module and each CPU. It uses multi-port memory modules to make this possible. The memory modules also have internal control logic to resolve when two or more CPUs simultaneously access memory words in the same memory module.</p><p style="padding-top: 4pt;padding-left: 38pt;text-indent: 0pt;text-align: justify;">This architecture enables fast memory access by multiple CPUs because of availability of multiple paths between processors and memory. However, it requires expensive memory control logic and a large number of cables and connectors. Hence, the complexity and cost of hardware grows rapidly with the increase in number of processors. Therefore, this architecture also does not scale well and is suitable only for systems with a small number of CPUs.</p><p style="padding-top: 4pt;padding-left: 38pt;text-indent: -15pt;text-align: justify;">4. <b>Crossbar  switch  architecture</b><i><b>.  </b></i><a href="part125.htm#bookmark1016" class="s23">The  bus-based  architectures  are  suitable  for multiprocessor systems having few tens of processors. Multiprocessor systems having few hundreds of processors use switch-based architecture instead of bus-based architecture. </a><a href="part125.htm#bookmark1016" class="s3">Figure </a><span class="s46">4.15</span>(d) shows one such architecture, which is known as crossbar switch architecture. In this architecture, there is a connection coming out of each CPU and each memory module and the system uses an electronic switch at every intersection point of the connections between CPUs and memory modules. Each switch has control logic to establish the transfer path between a processor and memory module and to resolve simultaneous access requests from multiple CPUs to the same memory module on a predetermined priority basis. This architecture supports simultaneous memory accesses by multiple CPUs because there is a separate path between each CPU and memory module. Hence, the architecture supports good scalability.</p><p style="padding-top: 4pt;padding-left: 38pt;text-indent: -15pt;text-align: justify;">5. <b>Omega switching network architecture. </b><a href="part125.htm#bookmark1016" class="s23">Notice from </a><a href="part125.htm#bookmark1016" class="s3">Figure </a><span class="s46">4.15</span>(d) that in the crossbar switch architecture, total 16 switches are required to interconnect 4 CPUs and 4 memory modules. In general, <i>n</i><span class="s31">2 </span>switches are required to interconnect <i>n </i>CPUs and <i>n </i>memory modules. Since the number of switches required grows exponentially with <i>n</i>, and because switches are costly electronic component, overall cost of a multiprocessor system using this architecture becomes prohibitive for large <i>n</i><a href="part515.htm#bookmark2408" class="s23">. Hence, multi-stage switching network architectures have been proposed and used to build large multiprocessor systems with fewer switches. One such architecture [shown in </a><a href="part515.htm#bookmark2408" class="s3">Figure </a><span class="s46">14.5</span><a href="part515.htm#bookmark2408" class="s23">(e)] is the Omega switching network architecture. In this architecture, only 4 switches are used to interconnect 4 CPUs and 4 memory modules as compared to 16 switches required in the crossbar switch architecture of </a><a href="part515.htm#bookmark2408" class="s3">Figure </a><span class="s46">14.5(d)</span>. Each switch is a 2x2 switch - has two inputs and two outputs with the capability to establish interconnection between any input to any output and to arbitrate between conflicting requests (if there are simultaneous requests from both the inputs to connect to the same output, only one of the them will be connected and the other will be blocked). With proper setting of switches, the system can establish a path between any CPU and memory module to enable memory access operation(s) between the two.</p><p style="padding-top: 4pt;padding-left: 39pt;text-indent: 0pt;text-align: justify;">Multi-stage switching network architectures can support large number of processors and memory modules with fewer switches. However, for large systems, a path between a CPU and memory module may have several switching stages, resulting in increase in memory</p><p style="padding-top: 3pt;padding-left: 39pt;text-indent: 0pt;text-align: left;">access time. Memory access operations being critical to overall system performance, a system usually keeps the number of switching stages low.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="nav">&nbsp;&nbsp;</p><p class="nav">&nbsp;</p><p class="nav"><a href="part124.htm">&lt; Назад</a><span> | </span><a href="../index.html">Содержимое</a><span> | </span><a href="part126.htm">Далее &gt;</a></p><p class="nav">&nbsp;&nbsp;</p></body></html>
